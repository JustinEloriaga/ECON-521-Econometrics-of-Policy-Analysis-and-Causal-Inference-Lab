{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c738de1",
   "metadata": {},
   "source": [
    "## Impact Evaluation (in Real Life)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12945264",
   "metadata": {},
   "source": [
    "Let us actually now try an understand how these things work in real life (at least the concepts we learned so far). The lecture is largely based from the book Impact Evaluation in Practice which is free to download from the World Bank website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ceb3a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locality_identifier</th>\n",
       "      <th>household_identifier</th>\n",
       "      <th>treatment_locality</th>\n",
       "      <th>promotion_locality</th>\n",
       "      <th>eligible</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>enrolled_rp</th>\n",
       "      <th>poverty_index</th>\n",
       "      <th>round</th>\n",
       "      <th>health_expenditures</th>\n",
       "      <th>...</th>\n",
       "      <th>educ_hh</th>\n",
       "      <th>educ_sp</th>\n",
       "      <th>female_hh</th>\n",
       "      <th>indigenous</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>dirtfloor</th>\n",
       "      <th>bathroom</th>\n",
       "      <th>land</th>\n",
       "      <th>hospital_distance</th>\n",
       "      <th>hospital</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.950542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.185455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124.819966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.950542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.580902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124.819966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.058731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.076257</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>124.819966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.058731</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.398854</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>124.819966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.095825</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>124.819966</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19822</th>\n",
       "      <td>35.0</td>\n",
       "      <td>15738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.737247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.811539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>162.748811</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19823</th>\n",
       "      <td>40.0</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.055641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.906003</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114.763392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19824</th>\n",
       "      <td>40.0</td>\n",
       "      <td>15769.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.055641</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.248152</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114.763392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19825</th>\n",
       "      <td>40.0</td>\n",
       "      <td>15778.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.828438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.737772</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>114.763392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19826</th>\n",
       "      <td>40.0</td>\n",
       "      <td>15778.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.828438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.366098</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>114.763392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19827 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       locality_identifier  household_identifier  treatment_locality  \\\n",
       "0                     26.0                   5.0                 1.0   \n",
       "1                     26.0                   5.0                 1.0   \n",
       "2                     26.0                  11.0                 1.0   \n",
       "3                     26.0                  11.0                 1.0   \n",
       "4                     26.0                  13.0                 1.0   \n",
       "...                    ...                   ...                 ...   \n",
       "19822                 35.0               15738.0                 0.0   \n",
       "19823                 40.0               15769.0                 1.0   \n",
       "19824                 40.0               15769.0                 1.0   \n",
       "19825                 40.0               15778.0                 1.0   \n",
       "19826                 40.0               15778.0                 1.0   \n",
       "\n",
       "       promotion_locality  eligible  enrolled  enrolled_rp  poverty_index  \\\n",
       "0                     1.0       1.0       1.0          1.0      55.950542   \n",
       "1                     1.0       1.0       1.0          1.0      55.950542   \n",
       "2                     1.0       1.0       1.0          0.0      46.058731   \n",
       "3                     1.0       1.0       1.0          0.0      46.058731   \n",
       "4                     1.0       1.0       1.0          0.0      54.095825   \n",
       "...                   ...       ...       ...          ...            ...   \n",
       "19822                 0.0       0.0       0.0          0.0      59.737247   \n",
       "19823                 1.0       0.0       0.0          0.0      62.055641   \n",
       "19824                 1.0       0.0       0.0          0.0      62.055641   \n",
       "19825                 1.0       0.0       0.0          0.0      62.828438   \n",
       "19826                 1.0       0.0       0.0          0.0      62.828438   \n",
       "\n",
       "       round  health_expenditures  ...  educ_hh  educ_sp  female_hh  \\\n",
       "0        0.0            15.185455  ...      0.0      6.0        0.0   \n",
       "1        1.0            19.580902  ...      0.0      6.0        0.0   \n",
       "2        0.0            13.076257  ...      4.0      0.0        0.0   \n",
       "3        1.0             2.398854  ...      4.0      0.0        0.0   \n",
       "4        1.0             0.000000  ...      0.0      0.0        0.0   \n",
       "...      ...                  ...  ...      ...      ...        ...   \n",
       "19822    0.0            16.811539  ...      0.0      2.0        0.0   \n",
       "19823    0.0            15.906003  ...      5.0      2.0        0.0   \n",
       "19824    1.0             8.248152  ...      5.0      2.0        0.0   \n",
       "19825    0.0             8.737772  ...      3.0      0.0        0.0   \n",
       "19826    1.0            10.366098  ...      3.0      0.0        0.0   \n",
       "\n",
       "       indigenous  hhsize  dirtfloor  bathroom  land  hospital_distance  \\\n",
       "0             0.0     4.0          1         0     1         124.819966   \n",
       "1             0.0     4.0          1         0     1         124.819966   \n",
       "2             0.0     6.0          1         0     2         124.819966   \n",
       "3             0.0     6.0          1         0     2         124.819966   \n",
       "4             0.0     6.0          1         0     4         124.819966   \n",
       "...           ...     ...        ...       ...   ...                ...   \n",
       "19822         1.0     7.0          0         1     2         162.748811   \n",
       "19823         1.0     5.0          1         1     1         114.763392   \n",
       "19824         1.0     5.0          1         1     1         114.763392   \n",
       "19825         1.0     9.0          1         1     4         114.763392   \n",
       "19826         1.0     9.0          1         1     4         114.763392   \n",
       "\n",
       "       hospital  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           1.0  \n",
       "4           1.0  \n",
       "...         ...  \n",
       "19822       NaN  \n",
       "19823       NaN  \n",
       "19824       NaN  \n",
       "19825       NaN  \n",
       "19826       NaN  \n",
       "\n",
       "[19827 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "\n",
    "df = pd.read_stata('evaluation.dta')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415cc3a",
   "metadata": {},
   "source": [
    "Here, we loaded the evaluation.dta dataset. Description and details on the dataset will be found online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bcc32d",
   "metadata": {},
   "source": [
    "**TASK 1**. Under this scenario, you will estimate the effect of the program by comparing the change in outcomes over time for a group of households that enrolled in the program. Assume full compliance, meaning that all of the households eligible for the program enrolled in it. Compare the average health expenditures before (round = 0) and after the program (round = 1) for the group eligible households (eligible =1) in treatment communities (treatment_locality = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e415aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average health expenditures before (round=0): 14.49\n",
      "Average health expenditures after (round=1): 7.84\n"
     ]
    }
   ],
   "source": [
    "# Filter for eligible households in treatment communities\n",
    "eligible_treatment = df[(df['eligible'] == 1) & (df['treatment_locality'] == 1)]\n",
    "\n",
    "# Calculate average health expenditures before (round=0) and after (round=1)\n",
    "avg_before = eligible_treatment[eligible_treatment['round'] == 0]['health_expenditures'].mean()\n",
    "avg_after = eligible_treatment[eligible_treatment['round'] == 1]['health_expenditures'].mean()\n",
    "\n",
    "print(f\"Average health expenditures before (round=0): {avg_before:.2f}\")\n",
    "print(f\"Average health expenditures after (round=1): {avg_after:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42d499",
   "metadata": {},
   "source": [
    "It turns out that when communities were being selected for inclusion in the health insurance pilot, there were many more eligible communities than could be covered with the available budget. The provincial authorities decided to run a lottery to select the communities that would participate in the insurance scheme in year 1, thus giving all communities a fair chance to start in the program first. Your data contains information on communities selected at random for participation in year 1, as well as on communities that would only enter the program in subsequent years.  The variable “treatment_locality” indicates treatment communities (treatment_locality = 1) and non-treatment or control communities (treatment_locality = 0). For this case, use both treatment and control communities in your analysis. The sample is structured as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af866773",
   "metadata": {},
   "source": [
    "|                     | Treatment Communities | Control Communities |\n",
    "|---------------------|-----------------------|---------------------|\n",
    "| **Eligible**        | 5,929                 | 5,328               |\n",
    "| **Ineligible**      | 3,990                 | 4,580               |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fc26a8",
   "metadata": {},
   "source": [
    "**TASK 2**. Compare baseline out of pocket health expenditures and other covariates between eligible households in treatment and control communities. Is the sample balanced on observables? Is this what you would expect and why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a38d8f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eligible × Treatment counts (all rounds):\n",
      "treatment_locality     0     1\n",
      "eligible                      \n",
      "0                   4580  3990\n",
      "1                   5328  5929\n",
      "\n",
      "[1] Baseline balance among ELIGIBLE (round==0)\n",
      "   mean_ctrl  mean_treat   diff    smd  pval_cluster\n",
      "0     14.574      14.490 -0.084 -0.020         0.693\n",
      "1     49.752      49.331 -0.421 -0.069         0.306\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make sure some keys are the expected dtypes\n",
    "df[\"round\"] = df[\"round\"].astype(int)\n",
    "df[\"eligible\"] = df[\"eligible\"].astype(int)\n",
    "df[\"treatment_locality\"] = df[\"treatment_locality\"].astype(int)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0) Sanity checks: sample structure and means by cells\n",
    "# -------------------------------------------------------------\n",
    "print(\"\\nEligible × Treatment counts (all rounds):\")\n",
    "print(pd.crosstab(df[\"eligible\"], df[\"treatment_locality\"]))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1) BASELINE BALANCE (round==0) among the ELIGIBLE population\n",
    "#    Compare treatment vs control on OOP and covariates.\n",
    "#    In a lottery, we expect no systematic differences at baseline\n",
    "#    (up to sampling noise). We'll show SMDs and clustered p-values.\n",
    "# -------------------------------------------------------------\n",
    "baseline = df.query(\"round == 0 and eligible == 1\").copy()\n",
    "\n",
    "# Choose a set of baseline variables to compare.\n",
    "# Feel free to add more here (e.g., household size, head/spouse edu/age) if present.\n",
    "cand_vars = [\n",
    "    \"health_expenditures\",   # baseline OOP\n",
    "    \"poverty_index\"\n",
    "]\n",
    "baseline_vars = [v for v in cand_vars if v in baseline.columns]\n",
    "\n",
    "def two_group_summary(data, var, treat=\"treatment_locality\"):\n",
    "    \"\"\"Return means by group, diff, standardized diff, and clustered p-value (cluster=locality_identifier).\"\"\"\n",
    "    g0 = data.loc[data[treat]==0, var].mean()\n",
    "    g1 = data.loc[data[treat]==1, var].mean()\n",
    "    diff = g1 - g0\n",
    "\n",
    "    # Std. mean diff (pooled SD)\n",
    "    s0 = data.loc[data[treat]==0, var].std()\n",
    "    s1 = data.loc[data[treat]==1, var].std()\n",
    "    n0 = data.loc[data[treat]==0, var].notna().sum()\n",
    "    n1 = data.loc[data[treat]==1, var].notna().sum()\n",
    "    sp = np.sqrt(((n0-1)*s0**2 + (n1-1)*s1**2) / (n0+n1-2)) if n0+n1-2 > 0 else np.nan\n",
    "    smd = diff / sp if sp>0 else np.nan\n",
    "\n",
    "    # Cluster-robust p-value from OLS(var ~ treatment), clustering by locality_identifier\n",
    "    model = smf.ols(f\"{var} ~ {treat}\", data=data).fit(\n",
    "        cov_type=\"cluster\",\n",
    "        cov_kwds={\"groups\": data[\"locality_identifier\"]}\n",
    "    )\n",
    "    pval = model.pvalues[treat]\n",
    "    return pd.Series({\"mean_ctrl\": g0, \"mean_treat\": g1, \"diff\": diff, \"smd\": smd, \"pval_cluster\": pval})\n",
    "\n",
    "balance_tbl = pd.concat(\n",
    "    [two_group_summary(baseline, v) for v in baseline_vars],\n",
    "    axis=1\n",
    ").T.round(3)\n",
    "print(\"\\n[1] Baseline balance among ELIGIBLE (round==0)\")\n",
    "print(balance_tbl)\n",
    "\n",
    "# Interpretation:\n",
    "# - If the lottery worked as intended, smd values should be small (|SMD| < 0.1 is commonly viewed as very balanced)\n",
    "#   and cluster-robust p-values should not show systematic differences.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52afe36c",
   "metadata": {},
   "source": [
    "**TASK 3**. In the treatment period (round =1), compare the average out of pocket health expenditures for the eligible population in treatment and control communities. Is this the impact of the health insurance program on out-of-pocket health expenditures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5fa4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Round 1 (treatment period) average OOP among ELIGIBLE:\n",
      "treatment_locality\n",
      "0    17.980551\n",
      "1     7.840179\n",
      "Name: health_expenditures, dtype: float32\n",
      "Difference (Treat - Control): -10.140\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 2) SIMPLE MEANS in treatment period (round==1), ELIGIBLE only\n",
    "#    (This is a raw ITT comparison, not yet controlling for anything.)\n",
    "# -------------------------------------------------------------\n",
    "t1 = df.query(\"round == 1 and eligible == 1\").copy()\n",
    "oop_means = t1.groupby(\"treatment_locality\")[\"health_expenditures\"].mean()\n",
    "diff_means = oop_means.get(1, np.nan) - oop_means.get(0, np.nan)\n",
    "print(\"\\n[2] Round 1 (treatment period) average OOP among ELIGIBLE:\")\n",
    "print(oop_means)\n",
    "print(f\"Difference (Treat - Control): {diff_means:.3f}\")\n",
    "\n",
    "# Note:\n",
    "# - This difference is the reduced-form ITT (intention-to-treat) contrast for eligible households.\n",
    "# - It is *not* necessarily the treatment-on-the-treated effect because not all eligible may enroll.\n",
    "# - We’ll estimate the ITT more formally via OLS with cluster-robust SE next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6fab82",
   "metadata": {},
   "source": [
    "**TASK 4**. Now use an OLS regression to estimate of the effect of the program on out-of-pocket health expenditures: (i). Without controls, (ii) Including characteristics of the household head and spouse, (iii) Including baseline covariates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7911c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLUSTER THINGS AND HOUSEKEEPING\n",
    "# ============================================================\n",
    "\n",
    "# Ensure key vars are ints (Stata-style 0/1 and round indicators)\n",
    "for c in [\"round\", \"eligible\", \"treatment_locality\", \"locality_identifier\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(int)\n",
    "\n",
    "def fit_cluster_ols(formula: str, data: pd.DataFrame, cluster_col: str):\n",
    "    \"\"\"\n",
    "    OLS with cluster-robust SEs, safely aligned to the exact rows used by the formula.\n",
    "    - Uses patsy.dmatrices to drop NAs on *only* the variables in `formula`.\n",
    "    - Then aligns the cluster vector to that same index (prevents length-mismatch errors).\n",
    "    \"\"\"\n",
    "    y, X = dmatrices(formula, data=data, return_type=\"dataframe\", NA_action=\"drop\")\n",
    "    groups = data.loc[y.index, cluster_col]\n",
    "    res = sm.OLS(y, X).fit(cov_type=\"cluster\", cov_kwds={\"groups\": groups})\n",
    "    return res\n",
    "\n",
    "# Convenience subsets\n",
    "eligible_r1 = df.query(\"eligible == 1 and round == 1\").copy()\n",
    "ineligible_r1 = df.query(\"eligible == 0 and round == 1\").copy()\n",
    "\n",
    "# Build baseline covariates (round==0) and merge when needed\n",
    "baseline = (\n",
    "    df.query(\"round == 0\")\n",
    "      .sort_values([\"household_identifier\", \"round\"])\n",
    "      .drop_duplicates(subset=[\"household_identifier\"])\n",
    "      .loc[:, [\"household_identifier\", \"health_expenditures\", \"poverty_index\"]]\n",
    "      .rename(columns={\n",
    "          \"health_expenditures\": \"bl_health_expenditures\",\n",
    "          \"poverty_index\": \"bl_poverty_index\"\n",
    "      })\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4d17db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     health_expenditures   R-squared:                       0.300\n",
      "Model:                             OLS   Adj. R-squared:                  0.300\n",
      "Method:                  Least Squares   F-statistic:                     656.8\n",
      "Date:                 Tue, 23 Sep 2025   Prob (F-statistic):           1.70e-64\n",
      "Time:                         22:08:25   Log-Likelihood:                -19497.\n",
      "No. Observations:                 5629   AIC:                         3.900e+04\n",
      "Df Residuals:                     5627   BIC:                         3.901e+04\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:               cluster                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             17.9806      0.307     58.638      0.000      17.380      18.582\n",
      "treatment_locality   -10.1404      0.396    -25.628      0.000     -10.916      -9.365\n",
      "==============================================================================\n",
      "Omnibus:                     2733.501   Durbin-Watson:                   1.703\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21489.300\n",
      "Skew:                           2.179   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.522   Cond. No.                         2.69\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Q3(i) — ELIGIBLE, ROUND 1: OLS without controls\n",
    "# Stata: reg health_expenditures treatment_locality if eligible==1 & round==1, cl(locality_identifier)\n",
    "# ============================================================\n",
    "form1 = \"health_expenditures ~ treatment_locality\"\n",
    "res1 = fit_cluster_ols(form1, eligible_r1, cluster_col=\"locality_identifier\")\n",
    "print(res1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620bfdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Controls used in Q3(ii): (none found)\n",
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     health_expenditures   R-squared:                       0.300\n",
      "Model:                             OLS   Adj. R-squared:                  0.300\n",
      "Method:                  Least Squares   F-statistic:                     656.8\n",
      "Date:                 Tue, 23 Sep 2025   Prob (F-statistic):           1.70e-64\n",
      "Time:                         22:08:34   Log-Likelihood:                -19497.\n",
      "No. Observations:                 5629   AIC:                         3.900e+04\n",
      "Df Residuals:                     5627   BIC:                         3.901e+04\n",
      "Df Model:                            1                                         \n",
      "Covariance Type:               cluster                                         \n",
      "======================================================================================\n",
      "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "Intercept             17.9806      0.307     58.638      0.000      17.380      18.582\n",
      "treatment_locality   -10.1404      0.396    -25.628      0.000     -10.916      -9.365\n",
      "==============================================================================\n",
      "Omnibus:                     2733.501   Durbin-Watson:                   1.703\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            21489.300\n",
      "Skew:                           2.179   Prob(JB):                         0.00\n",
      "Kurtosis:                      11.522   Cond. No.                         2.69\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Q3(ii) — ELIGIBLE, ROUND 1: OLS + HH head/spouse characteristics\n",
    "# Stata: reg health_expenditures treatment_locality $controls1 if eligible==1 & round==1, cl(locality_identifier)\n",
    "# NOTE: Edit the list below to match columns in your file; code keeps only those that exist.\n",
    "# ============================================================\n",
    "candidate_controls1 = [\n",
    "    # EXAMPLES — replace with your actual columns if present:\n",
    "    \"head_age\", \"head_education\", \"head_literate\",\n",
    "    \"spouse_age\", \"spouse_education\", \"spouse_literate\",\n",
    "    \"household_size\"\n",
    "]\n",
    "controls1 = [c for c in candidate_controls1 if c in eligible_r1.columns]\n",
    "\n",
    "form2 = \"health_expenditures ~ treatment_locality\" + ((\" + \" + \" + \".join(controls1)) if controls1 else \"\")\n",
    "print(\"Controls used in Q3(ii):\", controls1 if controls1 else \"(none found)\")\n",
    "res2 = fit_cluster_ols(form2, eligible_r1, cluster_col=\"locality_identifier\")\n",
    "print(res2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb0cd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head/Spouse controls in Q3(iii): (none)\n",
      "Baseline controls in Q3(iii):    ['bl_health_expenditures', 'bl_poverty_index']\n",
      "                             OLS Regression Results                            \n",
      "===============================================================================\n",
      "Dep. Variable:     health_expenditures   R-squared:                       0.429\n",
      "Model:                             OLS   Adj. R-squared:                  0.429\n",
      "Method:                  Least Squares   F-statistic:                     444.1\n",
      "Date:                 Tue, 23 Sep 2025   Prob (F-statistic):           4.08e-87\n",
      "Time:                         22:09:03   Log-Likelihood:                -18920.\n",
      "No. Observations:                 5628   AIC:                         3.785e+04\n",
      "Df Residuals:                     5624   BIC:                         3.788e+04\n",
      "Df Model:                            3                                         \n",
      "Covariance Type:               cluster                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                  5.8764      0.989      5.944      0.000       3.939       7.814\n",
      "treatment_locality       -10.0682      0.342    -29.423      0.000     -10.739      -9.398\n",
      "bl_health_expenditures     0.7617      0.032     23.446      0.000       0.698       0.825\n",
      "bl_poverty_index           0.0202      0.021      0.961      0.336      -0.021       0.061\n",
      "==============================================================================\n",
      "Omnibus:                     2649.332   Durbin-Watson:                   1.676\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            24651.616\n",
      "Skew:                           2.031   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.414   Cond. No.                         434.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "\n",
      "[Impact Q3(iii)] Coef on treatment_locality = -10.068\n",
      "Control mean (eligible, r1) = 17.981\n",
      "Percent change vs control mean = -55.99%\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Q3(iii) — ELIGIBLE, ROUND 1: OLS + HH head/spouse + BASELINE covariates\n",
    "# Stata: reg health_expenditures treatment_locality $controls if eligible==1 & round==1, cl(locality_identifier)\n",
    "# Baseline covariates are pre-program (round==0) values merged to round==1 rows.\n",
    "# ============================================================\n",
    "eligible_r1_bl = eligible_r1.merge(baseline, on=\"household_identifier\", how=\"left\")\n",
    "baseline_controls = [c for c in [\"bl_health_expenditures\", \"bl_poverty_index\"] if c in eligible_r1_bl.columns]\n",
    "\n",
    "form3_parts = [\"health_expenditures ~ treatment_locality\"]\n",
    "if controls1:         form3_parts.append(\" + \" + \" + \".join(controls1))\n",
    "if baseline_controls: form3_parts.append(\" + \" + \" + \".join(baseline_controls))\n",
    "form3 = \"\".join(form3_parts)\n",
    "\n",
    "print(\"Head/Spouse controls in Q3(iii):\", controls1 if controls1 else \"(none)\")\n",
    "print(\"Baseline controls in Q3(iii):   \", baseline_controls if baseline_controls else \"(none)\")\n",
    "res3 = fit_cluster_ols(form3, eligible_r1_bl, cluster_col=\"locality_identifier\")\n",
    "print(res3.summary())\n",
    "\n",
    "# Effect size as % of control mean (interpretation helper)\n",
    "ctrl_mean = eligible_r1_bl.loc[eligible_r1_bl[\"treatment_locality\"] == 0, \"health_expenditures\"].mean()\n",
    "b = res3.params.get(\"treatment_locality\", np.nan)\n",
    "pct = 100 * b / ctrl_mean if pd.notna(b) and ctrl_mean != 0 else np.nan\n",
    "print(f\"\\n[Impact Q3(iii)] Coef on treatment_locality = {b:.3f}\")\n",
    "print(f\"Control mean (eligible, r1) = {ctrl_mean:.3f}\")\n",
    "print(f\"Percent change vs control mean = {pct:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94c768",
   "metadata": {},
   "source": [
    "**TASK 5** What is the impact of the program on out-of-pocket health expenditures? What is the percent decrease that can be attributed to the program?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b892001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q4. Program Impact on Out-of-Pocket (Preferred spec: Q3(iii)) ===\n",
      "ITT impact (coef on treatment_locality): -10.068 currency units\n",
      "Cluster-robust SE: 0.342   p-value: 0.000\n",
      "95% CI for impact: [-10.739, -9.398]\n",
      "Control mean (eligible, round 1): 17.981\n",
      "\n",
      "Percent decrease vs control mean: -55.99% (95% CI: -59.72%, -52.26%)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Q4 — Program impact & percent decrease\n",
    "# Using the preferred spec from Q3(iii):\n",
    "#   Eligible households, round==1\n",
    "#   OLS: health_expenditures ~ treatment_locality + head/spouse chars + baseline covariates\n",
    "# Assumes you already ran Q3(iii) and have:\n",
    "#   - res3  : regression results object for the eligible sample with controls\n",
    "#   - eligible_r1_bl : the DataFrame used in Q3(iii) (eligible & round==1 with baseline merged)\n",
    "# =========================================\n",
    "\n",
    "# Coefficient on the treatment indicator is the ITT effect in currency units\n",
    "b = res3.params[\"treatment_locality\"]\n",
    "se = res3.bse[\"treatment_locality\"]\n",
    "p  = res3.pvalues[\"treatment_locality\"]\n",
    "ci_low, ci_high = res3.conf_int().loc[\"treatment_locality\"].tolist()\n",
    "\n",
    "# Control-group mean OOP (eligible, round 1) — for scaling to %\n",
    "control_mean = (\n",
    "    eligible_r1_bl.loc[eligible_r1_bl[\"treatment_locality\"] == 0, \"health_expenditures\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "# Percent change relative to the control mean\n",
    "pct = 100 * b / control_mean\n",
    "pct_low = 100 * ci_low / control_mean\n",
    "pct_high = 100 * ci_high / control_mean\n",
    "\n",
    "print(\"=== Q4. Program Impact on Out-of-Pocket (Preferred spec: Q3(iii)) ===\")\n",
    "print(f\"ITT impact (coef on treatment_locality): {b:,.3f} currency units\")\n",
    "print(f\"Cluster-robust SE: {se:,.3f}   p-value: {p:.3f}\")\n",
    "print(f\"95% CI for impact: [{ci_low:,.3f}, {ci_high:,.3f}]\")\n",
    "print(f\"Control mean (eligible, round 1): {control_mean:,.3f}\")\n",
    "\n",
    "direction = \"decrease\" if b < 0 else \"increase\"\n",
    "print(f\"\\nPercent {direction} vs control mean: {pct:.2f}% \"\n",
    "      f\"(95% CI: {pct_low:.2f}%, {pct_high:.2f}%)\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Interpretation notes (brief):\n",
    "# - b < 0 ⇒ the program reduced OOP by |pct| percent on average (ITT).\n",
    "# - This is an intention-to-treat effect: it reflects assignment of a\n",
    "#   locality to start the program in year 1, not necessarily take-up.\n",
    "# - For treatment-on-the-treated, you’d need an IV using assignment as\n",
    "#   an instrument for enrollment (not requested here).\n",
    "# ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff8c33",
   "metadata": {},
   "source": [
    "Let us say that the minister of health was pleased with the quality and results of the evaluation of the Health Insurance Subsidy Program (HISP). However, before scaling up the HISP, the government decides to pilot an expanded version of the program (which they call HISP+). HISP pays for part of the cost of health insurance for poor rural households, covering costs of primary care and drugs, but it does not cover hospitalization. The minister of health wonders whether an expanded HISP+ that also covers hospitalization would further lower out-of-pocket health expenditures. They ask you to design an impact evaluation to assess whether HISP+ further lowers health expenditures for poor rural households. In this case, choosing an impact evaluation design is not a challenge for you: HISP+ has limited resources and cannot be implemented universally immediately. As a result, you have concluded that randomized assignment would be the most viable and robust impact evaluation method. The minister of health understands how well the randomized assignment method works and is supportive. To ﬁnalize the design of the impact evaluation, you need to determine how big a sample is needed. Note that since we are using a random assignment scenario, you can drop the ineligible (eligible = 0) households from the dataset to simplify your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd330d6",
   "metadata": {},
   "source": [
    "**TASK 6** Use data from the follow-up HISP survey to obtain the benchmark mean and standard deviation for the two outcome indicators of interest to the minister of health—health expenditures and hospitalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c048fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q1. Benchmarks from follow-up (treated, eligible only) ===\n",
      "Health exp — mean = 7.840,  SD = 7.994\n",
      "Hospital    — mean = 0.049 (4.9%),  SD = 0.215\n",
      "\n",
      "Interpretation: These are the reference mean and variability used to size the trial. Higher SDs or smaller MDEs will require larger samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0) Keep only eligible households\n",
    "df_e = df.loc[df[\"eligible\"] == 1].copy()\n",
    "\n",
    "# 1) Benchmarks from follow-up HISP survey (round==1) — in the treatment arm\n",
    "followup_treat = df_e.query(\"round == 1 and treatment_locality == 1\").copy()\n",
    "\n",
    "# Hospitalization variable name can be 'hospital' or 'hospitalization' depending on the file\n",
    "hosp_col = \"hospital\" if \"hospital\" in followup_treat.columns else \"hospitalization\"\n",
    "\n",
    "m1_exp = followup_treat[\"health_expenditures\"].mean()           # mean OOP in treated at follow-up\n",
    "sd_exp = followup_treat[\"health_expenditures\"].std(ddof=1)      # SD OOP (used for both arms in power calc)\n",
    "\n",
    "m1_h   = followup_treat[hosp_col].mean()                         # hospitalization rate in treated (0–1)\n",
    "sd_h   = followup_treat[hosp_col].std(ddof=1)                    # SD of the binary outcome (≈ sqrt(p*(1-p)))\n",
    "\n",
    "print(\"=== Q1. Benchmarks from follow-up (treated, eligible only) ===\")\n",
    "print(f\"Health exp — mean = {m1_exp:,.3f},  SD = {sd_exp:,.3f}\")\n",
    "print(f\"Hospital    — mean = {m1_h:.3f} ({100*m1_h:.1f}%),  SD = {sd_h:.3f}\")\n",
    "print(\"\\nInterpretation: These are the reference mean and variability used to size the trial. \"\n",
    "      \"Higher SDs or smaller MDEs will require larger samples.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6731e38",
   "metadata": {},
   "source": [
    "**TASK 7**. Determine the sample size needed for a minimum detectable effect of $1, $2, and $3 decrease in household out-of pocket health expenditures. Compare the sample sizes required depending on the power level you use, 0.8 or 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1db3590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Helper: sample size per group for a two-sample difference in means\n",
    "# Uses the same SD for both arms and equal allocation (ratio=1), α=0.05.\n",
    "# This matches Stata: sampsi m1 m2, r(1) sd1(sd) sd2(sd)\n",
    "# -------------------------------------------------------------------\n",
    "power_calc = TTestIndPower()\n",
    "ALPHA = 0.05\n",
    "\n",
    "def n_per_group_from_mde(sd, mde, power):\n",
    "    \"\"\"\n",
    "    sd   : common standard deviation for the outcome\n",
    "    mde  : absolute difference you want to detect (|μ_T - μ_C|)\n",
    "    power: desired power (e.g., 0.8 or 0.9)\n",
    "    Returns: required sample size per group (floated; round up in practice).\n",
    "    \"\"\"\n",
    "    effect_size = mde / sd\n",
    "    # solve_power returns the required n in the *first* group; with ratio=1 this is per group\n",
    "    n = power_calc.solve_power(effect_size=effect_size, alpha=ALPHA,\n",
    "                               power=power, ratio=1.0, alternative=\"two-sided\")\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9dc9c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q2. Required sample sizes for OOP expenditures (eligible only) ===\n",
      "            Outcome  MDE (currency units)  Power  N per group (equal arms)  N total (2 arms)\n",
      "Health expenditures                   1.0    0.8                    1005.0              2009\n",
      "Health expenditures                   2.0    0.8                     252.0               504\n",
      "Health expenditures                   3.0    0.8                     113.0               225\n",
      "Health expenditures                   1.0    0.9                    1345.0              2689\n",
      "Health expenditures                   2.0    0.9                     337.0               674\n",
      "Health expenditures                   3.0    0.9                     151.0               301\n",
      "\n",
      "Implication: Detecting smaller dollar changes requires disproportionately larger samples. At a fixed MDE, moving from 80% to 90% power increases the required sample size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2) Expenditures — MDEs of $1, $2, $3; power 0.8 and 0.9\n",
    "mde_exp_list = [1.0, 2.0, 3.0]\n",
    "powers = [0.8, 0.9]\n",
    "\n",
    "rows_exp = []\n",
    "for pwr in powers:\n",
    "    for mde in mde_exp_list:\n",
    "        n_pg = n_per_group_from_mde(sd=sd_exp, mde=mde, power=pwr)\n",
    "        rows_exp.append({\"Outcome\":\"Health expenditures\",\n",
    "                         \"MDE (currency units)\": mde,\n",
    "                         \"Power\": pwr,\n",
    "                         \"N per group (equal arms)\": np.ceil(n_pg),\n",
    "                         \"N total (2 arms)\": int(np.ceil(2*n_pg))})\n",
    "exp_table = pd.DataFrame(rows_exp)\n",
    "print(\"=== Q2. Required sample sizes for OOP expenditures (eligible only) ===\")\n",
    "print(exp_table.to_string(index=False))\n",
    "print(\"\\nImplication: Detecting smaller dollar changes requires disproportionately larger samples. \"\n",
    "      \"At a fixed MDE, moving from 80% to 90% power increases the required sample size.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0b73a",
   "metadata": {},
   "source": [
    "**TASK 8**. Determine the sample size needed for a minimum detectable effect of 1%, 2%, and 3% increases in the hospitalization rate. Compare the sample sizes required depending on the power level you use, 0.8 or 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7628b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Q3. Required sample sizes for hospitalization rate (eligible only) ===\n",
      "             Outcome MDE (abs. points)  Power  N per group (equal arms)  N total (2 arms)\n",
      "Hospitalization rate              1 pp    0.8                    7257.0             14514\n",
      "Hospitalization rate              2 pp    0.8                    1815.0              3630\n",
      "Hospitalization rate              3 pp    0.8                     808.0              1615\n",
      "Hospitalization rate              1 pp    0.9                    9715.0             19430\n",
      "Hospitalization rate              2 pp    0.9                    2430.0              4859\n",
      "Hospitalization rate              3 pp    0.9                    1081.0              2161\n",
      "\n",
      "Implication: Because hospitalization is relatively rare, its SD is tied to p(1-p). Smaller MDEs in percentage points demand very large samples; increasing target power from 0.80 to 0.90 also raises the sample size notably.\n",
      "\n",
      "Design notes:\n",
      "* Use equal allocation unless logistics argue otherwise; with fixed total N, equal arms maximize power.\n",
      "* If your pilot suggests clustering (e.g., village-level randomization), inflate N using a design effect:\n",
      "    DEFF = 1 + (m - 1) * ICC   (m = cluster size, ICC = intra-cluster correlation).\n",
      "* The tables above report simple individual-level calculations; adjust upward if clustering or attrition is expected.\n"
     ]
    }
   ],
   "source": [
    "# 3) Hospitalization — MDEs of +1, +2, +3 percentage points\n",
    "#    We follow the same 'two means with common SD' approach as in the Stata script:\n",
    "#    treat hospitalization as continuous (0/1) and use sd_h for both arms.\n",
    "mde_pp = [0.01, 0.02, 0.03]  # absolute differences (e.g., +0.01 = +1 percentage point)\n",
    "\n",
    "rows_h = []\n",
    "for pwr in powers:\n",
    "    for mde in mde_pp:\n",
    "        n_pg = n_per_group_from_mde(sd=sd_h, mde=mde, power=pwr)\n",
    "        rows_h.append({\"Outcome\":\"Hospitalization rate\",\n",
    "                       \"MDE (abs. points)\": f\"{int(mde*100)} pp\",\n",
    "                       \"Power\": pwr,\n",
    "                       \"N per group (equal arms)\": np.ceil(n_pg),\n",
    "                       \"N total (2 arms)\": int(np.ceil(2*n_pg))})\n",
    "hosp_table = pd.DataFrame(rows_h)\n",
    "print(\"=== Q3. Required sample sizes for hospitalization rate (eligible only) ===\")\n",
    "print(hosp_table.to_string(index=False))\n",
    "print(\"\\nImplication: Because hospitalization is relatively rare, its SD is tied to p(1-p). \"\n",
    "      \"Smaller MDEs in percentage points demand very large samples; increasing target power \"\n",
    "      \"from 0.80 to 0.90 also raises the sample size notably.\\n\")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Quick design takeaways (printed as comments)\n",
    "# -------------------------------------------\n",
    "print(\"Design notes:\")\n",
    "print(\"* Use equal allocation unless logistics argue otherwise; with fixed total N, equal arms maximize power.\")\n",
    "print(\"* If your pilot suggests clustering (e.g., village-level randomization), inflate N using a design effect:\")\n",
    "print(\"    DEFF = 1 + (m - 1) * ICC   (m = cluster size, ICC = intra-cluster correlation).\")\n",
    "print(\"* The tables above report simple individual-level calculations; adjust upward if clustering or attrition is expected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
